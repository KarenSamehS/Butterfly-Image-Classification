{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-06T23:42:32.297613Z",
     "iopub.status.busy": "2025-02-06T23:42:32.297320Z",
     "iopub.status.idle": "2025-02-06T23:42:33.662817Z",
     "shell.execute_reply": "2025-02-06T23:42:33.661729Z",
     "shell.execute_reply.started": "2025-02-06T23:42:32.297579Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:28:30.135442Z",
     "iopub.status.busy": "2025-02-10T02:28:30.135163Z",
     "iopub.status.idle": "2025-02-10T02:28:34.203323Z",
     "shell.execute_reply": "2025-02-10T02:28:34.202527Z",
     "shell.execute_reply.started": "2025-02-10T02:28:30.135395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:28:34.204440Z",
     "iopub.status.busy": "2025-02-10T02:28:34.204156Z",
     "iopub.status.idle": "2025-02-10T02:28:52.098996Z",
     "shell.execute_reply": "2025-02-10T02:28:52.098107Z",
     "shell.execute_reply.started": "2025-02-10T02:28:34.204393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets ,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:28:52.101243Z",
     "iopub.status.busy": "2025-02-10T02:28:52.100718Z",
     "iopub.status.idle": "2025-02-10T02:28:52.160541Z",
     "shell.execute_reply": "2025-02-10T02:28:52.159791Z",
     "shell.execute_reply.started": "2025-02-10T02:28:52.101217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.jpg: 224x224\n",
      "1.jpg: 224x224\n",
      "4.jpg: 224x224\n",
      "3.jpg: 224x224\n",
      "2.jpg: 224x224\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define your folder path\n",
    "folder_path = \"/kaggle/input/butterfly-images40-species/valid/ADONIS\"\n",
    "\n",
    "# Loop through each image in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Check if it's a file and has an image extension\n",
    "    if os.path.isfile(file_path) and file_name.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'tiff')):\n",
    "        with Image.open(file_path) as img:\n",
    "            width, height = img.size\n",
    "            print(f\"{file_name}: {width}x{height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:28:52.162100Z",
     "iopub.status.busy": "2025-02-10T02:28:52.161855Z",
     "iopub.status.idle": "2025-02-10T02:28:52.166754Z",
     "shell.execute_reply": "2025-02-10T02:28:52.165808Z",
     "shell.execute_reply.started": "2025-02-10T02:28:52.162078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize image to 128x128\n",
    "    transforms.RandomHorizontalFlip(),  # Random flip for augmentation\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalization\n",
    "])\n",
    "\n",
    "valid_test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize image to 128x128\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalization\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Datasets Using ImageFolder: The ImageFolder class will automatically load the images and label them based on the folder names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:28:52.167935Z",
     "iopub.status.busy": "2025-02-10T02:28:52.167644Z",
     "iopub.status.idle": "2025-02-10T02:29:01.412534Z",
     "shell.execute_reply": "2025-02-10T02:29:01.411814Z",
     "shell.execute_reply.started": "2025-02-10T02:28:52.167903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load train, validation, and test datasets\n",
    "train_dataset = datasets.ImageFolder(root='/kaggle/input/butterfly-images40-species/train', transform=train_transform)\n",
    "valid_dataset = datasets.ImageFolder(root='/kaggle/input/butterfly-images40-species/valid', transform=valid_test_transform)\n",
    "test_dataset = datasets.ImageFolder(root='/kaggle/input/butterfly-images40-species/test', transform=valid_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:29:01.413581Z",
     "iopub.status.busy": "2025-02-10T02:29:01.413344Z",
     "iopub.status.idle": "2025-02-10T02:29:01.417928Z",
     "shell.execute_reply": "2025-02-10T02:29:01.417105Z",
     "shell.execute_reply.started": "2025-02-10T02:29:01.413562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders for train, validation, and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:29:01.419078Z",
     "iopub.status.busy": "2025-02-10T02:29:01.418782Z",
     "iopub.status.idle": "2025-02-10T02:29:02.041420Z",
     "shell.execute_reply": "2025-02-10T02:29:02.040370Z",
     "shell.execute_reply.started": "2025-02-10T02:29:01.419048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Get a batch from the train loader\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Displaying the batch shape\n",
    "print(images.shape)  # Shape will be [batch_size, channels, height, width]\n",
    "print(labels.shape)  # Shape will be [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:29:02.044339Z",
     "iopub.status.busy": "2025-02-10T02:29:02.044074Z",
     "iopub.status.idle": "2025-02-10T02:29:02.050023Z",
     "shell.execute_reply": "2025-02-10T02:29:02.049158Z",
     "shell.execute_reply.started": "2025-02-10T02:29:02.044309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 100\n",
      "Class names: ['ADONIS', 'AFRICAN GIANT SWALLOWTAIL', 'AMERICAN SNOOT', 'AN 88', 'APPOLLO', 'ARCIGERA FLOWER MOTH', 'ATALA', 'ATLAS MOTH', 'BANDED ORANGE HELICONIAN', 'BANDED PEACOCK', 'BANDED TIGER MOTH', 'BECKERS WHITE', 'BIRD CHERRY ERMINE MOTH', 'BLACK HAIRSTREAK', 'BLUE MORPHO', 'BLUE SPOTTED CROW', 'BROOKES BIRDWING', 'BROWN ARGUS', 'BROWN SIPROETA', 'CABBAGE WHITE', 'CAIRNS BIRDWING', 'CHALK HILL BLUE', 'CHECQUERED SKIPPER', 'CHESTNUT', 'CINNABAR MOTH', 'CLEARWING MOTH', 'CLEOPATRA', 'CLODIUS PARNASSIAN', 'CLOUDED SULPHUR', 'COMET MOTH', 'COMMON BANDED AWL', 'COMMON WOOD-NYMPH', 'COPPER TAIL', 'CRECENT', 'CRIMSON PATCH', 'DANAID EGGFLY', 'EASTERN COMA', 'EASTERN DAPPLE WHITE', 'EASTERN PINE ELFIN', 'ELBOWED PIERROT', 'EMPEROR GUM MOTH', 'GARDEN TIGER MOTH', 'GIANT LEOPARD MOTH', 'GLITTERING SAPPHIRE', 'GOLD BANDED', 'GREAT EGGFLY', 'GREAT JAY', 'GREEN CELLED CATTLEHEART', 'GREEN HAIRSTREAK', 'GREY HAIRSTREAK', 'HERCULES MOTH', 'HUMMING BIRD HAWK MOTH', 'INDRA SWALLOW', 'IO MOTH', 'Iphiclus sister', 'JULIA', 'LARGE MARBLE', 'LUNA MOTH', 'MADAGASCAN SUNSET MOTH', 'MALACHITE', 'MANGROVE SKIPPER', 'MESTRA', 'METALMARK', 'MILBERTS TORTOISESHELL', 'MONARCH', 'MOURNING CLOAK', 'OLEANDER HAWK MOTH', 'ORANGE OAKLEAF', 'ORANGE TIP', 'ORCHARD SWALLOW', 'PAINTED LADY', 'PAPER KITE', 'PEACOCK', 'PINE WHITE', 'PIPEVINE SWALLOW', 'POLYPHEMUS MOTH', 'POPINJAY', 'PURPLE HAIRSTREAK', 'PURPLISH COPPER', 'QUESTION MARK', 'RED ADMIRAL', 'RED CRACKER', 'RED POSTMAN', 'RED SPOTTED PURPLE', 'ROSY MAPLE MOTH', 'SCARCE SWALLOW', 'SILVER SPOT SKIPPER', 'SIXSPOT BURNET MOTH', 'SLEEPY ORANGE', 'SOOTYWING', 'SOUTHERN DOGFACE', 'STRAITED QUEEN', 'TROPICAL LEAFWING', 'TWO BARRED FLASHER', 'ULYSES', 'VICEROY', 'WHITE LINED SPHINX MOTH', 'WOOD SATYR', 'YELLOW SWALLOW TAIL', 'ZEBRA LONG WING']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Print class names\n",
    "print(\"Class names:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:29:02.051857Z",
     "iopub.status.busy": "2025-02-10T02:29:02.051480Z",
     "iopub.status.idle": "2025-02-10T02:29:02.211239Z",
     "shell.execute_reply": "2025-02-10T02:29:02.210462Z",
     "shell.execute_reply.started": "2025-02-10T02:29:02.051824Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Adjust size based on image size\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):   #x -> tensor ely hasht8l 3leha \n",
    "       # print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten for Fully Connected Layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation (CrossEntropyLoss includes softmax)\n",
    "        \n",
    "        return x\n",
    "num_classes = 100\n",
    "model = CustomCNN(num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:29:02.212362Z",
     "iopub.status.busy": "2025-02-10T02:29:02.212084Z",
     "iopub.status.idle": "2025-02-10T02:29:02.477904Z",
     "shell.execute_reply": "2025-02-10T02:29:02.477187Z",
     "shell.execute_reply.started": "2025-02-10T02:29:02.212329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:35:06.211593Z",
     "iopub.status.busy": "2025-02-10T02:35:06.211155Z",
     "iopub.status.idle": "2025-02-10T02:43:10.809295Z",
     "shell.execute_reply": "2025-02-10T02:43:10.808382Z",
     "shell.execute_reply.started": "2025-02-10T02:35:06.211549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.0909\n",
      " Validation Loss: 1.9345, Validation Accuracy: 75.40%\n",
      "Epoch [2/100], Training Loss: 0.0968\n",
      " Validation Loss: 1.6866, Validation Accuracy: 75.60%\n",
      "Epoch [3/100], Training Loss: 0.0850\n",
      " Validation Loss: 1.8099, Validation Accuracy: 75.20%\n",
      "No improvement in validation loss. Epochs without improvement: 1\n",
      "Epoch [4/100], Training Loss: 0.0936\n",
      " Validation Loss: 1.9214, Validation Accuracy: 74.60%\n",
      "No improvement in validation loss. Epochs without improvement: 2\n",
      "Epoch [5/100], Training Loss: 0.0705\n",
      " Validation Loss: 2.0492, Validation Accuracy: 77.20%\n",
      "No improvement in validation loss. Epochs without improvement: 3\n",
      "Epoch [6/100], Training Loss: 0.0877\n",
      " Validation Loss: 1.7705, Validation Accuracy: 75.80%\n",
      "No improvement in validation loss. Epochs without improvement: 4\n",
      "Epoch [7/100], Training Loss: 0.0771\n",
      " Validation Loss: 2.3182, Validation Accuracy: 72.20%\n",
      "No improvement in validation loss. Epochs without improvement: 5\n",
      "Epoch [8/100], Training Loss: 0.0785\n",
      " Validation Loss: 1.9610, Validation Accuracy: 74.00%\n",
      "No improvement in validation loss. Epochs without improvement: 6\n",
      "Epoch [9/100], Training Loss: 0.0821\n",
      " Validation Loss: 1.7161, Validation Accuracy: 74.80%\n",
      "Learning Rate changed from 0.001000 to 0.000500\n",
      "No improvement in validation loss. Epochs without improvement: 7\n",
      "Epoch [10/100], Training Loss: 0.0239\n",
      " Validation Loss: 1.6721, Validation Accuracy: 76.60%\n",
      "Epoch [11/100], Training Loss: 0.0074\n",
      " Validation Loss: 1.6709, Validation Accuracy: 78.20%\n",
      "Epoch [12/100], Training Loss: 0.0041\n",
      " Validation Loss: 1.6292, Validation Accuracy: 79.20%\n",
      "Epoch [13/100], Training Loss: 0.0013\n",
      " Validation Loss: 1.7732, Validation Accuracy: 78.60%\n",
      "No improvement in validation loss. Epochs without improvement: 1\n",
      "Epoch [14/100], Training Loss: 0.0008\n",
      " Validation Loss: 1.7642, Validation Accuracy: 79.60%\n",
      "No improvement in validation loss. Epochs without improvement: 2\n",
      "Epoch [15/100], Training Loss: 0.0006\n",
      " Validation Loss: 1.8130, Validation Accuracy: 80.20%\n",
      "No improvement in validation loss. Epochs without improvement: 3\n",
      "Epoch [16/100], Training Loss: 0.0016\n",
      " Validation Loss: 1.7965, Validation Accuracy: 78.40%\n",
      "No improvement in validation loss. Epochs without improvement: 4\n",
      "Epoch [17/100], Training Loss: 0.0297\n",
      " Validation Loss: 1.9127, Validation Accuracy: 77.60%\n",
      "No improvement in validation loss. Epochs without improvement: 5\n",
      "Epoch [18/100], Training Loss: 0.0264\n",
      " Validation Loss: 2.1460, Validation Accuracy: 77.20%\n",
      "No improvement in validation loss. Epochs without improvement: 6\n",
      "Epoch [19/100], Training Loss: 0.0148\n",
      " Validation Loss: 1.9891, Validation Accuracy: 78.20%\n",
      "Learning Rate changed from 0.000500 to 0.000250\n",
      "No improvement in validation loss. Epochs without improvement: 7\n",
      "Epoch [20/100], Training Loss: 0.0035\n",
      " Validation Loss: 1.9174, Validation Accuracy: 79.20%\n",
      "No improvement in validation loss. Epochs without improvement: 8\n",
      "Epoch [21/100], Training Loss: 0.0008\n",
      " Validation Loss: 1.9155, Validation Accuracy: 79.40%\n",
      "No improvement in validation loss. Epochs without improvement: 9\n",
      "Epoch [22/100], Training Loss: 0.0009\n",
      " Validation Loss: 2.0006, Validation Accuracy: 77.00%\n",
      "No improvement in validation loss. Epochs without improvement: 10\n",
      "Epoch [23/100], Training Loss: 0.0012\n",
      " Validation Loss: 2.0634, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 11\n",
      "Epoch [24/100], Training Loss: 0.0002\n",
      " Validation Loss: 2.0000, Validation Accuracy: 78.80%\n",
      "No improvement in validation loss. Epochs without improvement: 12\n",
      "Epoch [25/100], Training Loss: 0.0004\n",
      " Validation Loss: 2.0229, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 13\n",
      "Epoch [26/100], Training Loss: 0.0001\n",
      " Validation Loss: 2.0542, Validation Accuracy: 78.60%\n",
      "Learning Rate changed from 0.000250 to 0.000125\n",
      "No improvement in validation loss. Epochs without improvement: 14\n",
      "Epoch [27/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0569, Validation Accuracy: 78.80%\n",
      "No improvement in validation loss. Epochs without improvement: 15\n",
      "Epoch [28/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0633, Validation Accuracy: 78.80%\n",
      "No improvement in validation loss. Epochs without improvement: 16\n",
      "Epoch [29/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0703, Validation Accuracy: 78.60%\n",
      "No improvement in validation loss. Epochs without improvement: 17\n",
      "Epoch [30/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0762, Validation Accuracy: 78.60%\n",
      "No improvement in validation loss. Epochs without improvement: 18\n",
      "Epoch [31/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0869, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 19\n",
      "Epoch [32/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.0989, Validation Accuracy: 78.80%\n",
      "No improvement in validation loss. Epochs without improvement: 20\n",
      "Epoch [33/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.1108, Validation Accuracy: 78.80%\n",
      "Learning Rate changed from 0.000125 to 0.000063\n",
      "No improvement in validation loss. Epochs without improvement: 21\n",
      "Epoch [34/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.1174, Validation Accuracy: 78.80%\n",
      "No improvement in validation loss. Epochs without improvement: 22\n",
      "Epoch [35/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.1235, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 23\n",
      "Epoch [36/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.1298, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 24\n",
      "Epoch [37/100], Training Loss: 0.0000\n",
      " Validation Loss: 2.1397, Validation Accuracy: 79.00%\n",
      "No improvement in validation loss. Epochs without improvement: 25\n",
      "Early stopping triggered after  25, epochs without improvement!\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"./logs\")  # Creates a TensorBoard log directory\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning Rate Scheduler (Reduce LR if validation loss stops improving)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=6, factor=0.5, verbose=True)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 25  # Number of epochs to wait before stopping if no improvement\n",
    "best_val_loss = np.inf  # Track the best validation loss\n",
    "epochs_no_improve = 0  # Count epochs without improvemen\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    writer.add_scalar(\"Loss/train\", running_loss / len(train_loader), epoch)\n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss=0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(valid_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\" Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    writer.add_scalar(\"Loss/valid\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/valid\", accuracy, epoch)\n",
    "    \n",
    "    # Reduce learning rate if validation loss stops improving\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Print when LR changes\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"Learning Rate changed from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation loss. Epochs without improvement: {epochs_no_improve}\")\n",
    "\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after  {epochs_no_improve}, epochs without improvement!\")\n",
    "        break  # Stop training if no improvement\n",
    "print(\"Training complete!\")\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:43:10.811108Z",
     "iopub.status.busy": "2025-02-10T02:43:10.810775Z",
     "iopub.status.idle": "2025-02-10T02:43:11.440198Z",
     "shell.execute_reply": "2025-02-10T02:43:11.439200Z",
     "shell.execute_reply.started": "2025-02-10T02:43:10.811073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.00%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():  # No gradient computation during testing\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = test_correct / test_total * 100\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:34:22.840765Z",
     "iopub.status.busy": "2025-02-10T02:34:22.840492Z",
     "iopub.status.idle": "2025-02-10T02:34:22.989626Z",
     "shell.execute_reply": "2025-02-10T02:34:22.988741Z",
     "shell.execute_reply.started": "2025-02-10T02:34:22.840741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: logs/ (stored 0%)\n",
      "  adding: logs/events.out.tfevents.1739154542.fe2d06c5b425.31.0 (deflated 63%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r logs.zip ./logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T02:34:22.991004Z",
     "iopub.status.busy": "2025-02-10T02:34:22.990689Z",
     "iopub.status.idle": "2025-02-10T02:34:23.137010Z",
     "shell.execute_reply": "2025-02-10T02:34:23.136138Z",
     "shell.execute_reply.started": "2025-02-10T02:34:22.990978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs:\n",
      "events.out.tfevents.1739154542.fe2d06c5b425.31.0\n"
     ]
    }
   ],
   "source": [
    "!ls -R ./logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###RUNLOCALLY with command\n",
    "C:\\Users\\username\\AppData\\Roaming\\Python\\Python312\\Scripts\\tensorboard.exe --logdir=logs\n",
    "\n",
    "then open http://localhost:6006/ in your browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 456014,
     "sourceId": 5481697,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
